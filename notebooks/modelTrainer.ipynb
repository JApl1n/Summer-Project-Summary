{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data by running \n",
    "\n",
    "./sampler.py --density 0.1\n",
    "./sampler.py --density 0.1 --odd \n",
    "\n",
    "to generate a datset in the folder 'data' with all tumbling rates. Now we have the data we want to train a model on it using the architecture designed. To do this run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPooling2D,BatchNormalization,AveragePooling2D,LeakyReLU,GlobalAveragePooling2D,ReLU\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPooling2D,BatchNormalization,AveragePooling2D,Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloading\n",
    "\n",
    "def extract_floats(string):\n",
    "    return re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", string)\n",
    "\n",
    "def data_load():\n",
    "    density = 0.15\n",
    "    files = glob.glob(f\"../data/dataset_tumble_*_0.1_1000.h5\") #imports all tumbling rates for density 0.1 with 250 snapshots\n",
    "    inputs,outputs = [],[]\n",
    "    for f in files:\n",
    "        tumble = float(extract_floats(f)[0])\n",
    "        with h5py.File(f, \"r\") as fin:\n",
    "          count = 0\n",
    "          for key in fin.keys():\n",
    "              img = fin[key][:]\n",
    "              img = img.reshape((img.shape[0], img.shape[1],1))\n",
    "              shape = img.shape\n",
    "              inputs.append(img)\n",
    "              outputs.append(tumble)\n",
    "              count+=1\n",
    "\n",
    "    # Scramble the dataset\n",
    "    order = np.arange(len(outputs)).astype(int)\n",
    "    order = np.random.permutation(order)\n",
    "    return np.array(inputs)[order],np.array(outputs)[order],shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,shape = data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up test train split\n",
    "last = int(np.shape(y)[0]*0.2) # 80% train data\n",
    "x_train, y_train = x[:-last], y[:-last]\n",
    "x_val,y_val = x[-last:],y[-last:]\n",
    "\n",
    "print(\"Size of training data: \", len(x_train))\n",
    "print(\"Size of validation data: \", len(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Options\n",
    "import contextlib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def options(options):\n",
    "  old_opts = tf.config.optimizer.get_experimental_options()\n",
    "  tf.config.optimizer.set_experimental_options(options)\n",
    "  try:\n",
    "    yield\n",
    "  finally:\n",
    "    tf.config.optimizer.set_experimental_options(old_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this after analysis to reset model and release RAM before changing the architecture\n",
    "import gc\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "print(\"Collected: \", gc.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Architecture\n",
    "\n",
    "fixed_seed = 296 #choose seed (comment out if not needed)\n",
    "\n",
    "if 'fixed_seed' in locals():\n",
    "    keras.utils.set_random_seed(fixed_seed)\n",
    "    print(\"Running program with fixed seed:\",fixed_seed)\n",
    "else:\n",
    "    print(\"Running program with random seed.\")\n",
    "\n",
    "def make_net(shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=3, kernel_size=(3,3), padding='same', strides=(3,3), activation='relu', input_shape=shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=3, kernel_size=(3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    #model.add(AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "    # with options({\"layout_optimizer\": False}):\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_net(shape)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add optimiser\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    verbose=True,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output learningCurve values if needed\n",
    "\n",
    "# f = open(\"learningCurves.txt\", \"a\")\n",
    "# f.write(\"labelName\") \n",
    "# for value in history.history[\"val_loss\"]: f.write(\",\"+str(value))  # Replace \"val_loss\" with \"loss\" for training loss\n",
    "# f.write(\"\\n\")\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively load pre-trained model (comment out previous cell to save time)\n",
    "\n",
    "# name = \"modelName\"\n",
    "# model = tf.keras.models.load_model(f'../models/{name}.keras')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse training results\n",
    "\n",
    "prediction = model.predict(x_val, batch_size=64)\n",
    "print(\"Shape of prediction : \", np.shape(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "model.save(\"../models/modelName.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
