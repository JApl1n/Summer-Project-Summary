{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loading\n",
    "def extract_floats(string):\n",
    "    return re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", string)\n",
    "\n",
    "def data_load():\n",
    "    density = 0.15\n",
    "    files = glob.glob(f\"../data/dataset_tumble_*_0.1_1000.h5\") # IDeally this would be a test set to completely separate it from the training data\n",
    "    inputs,outputs = [],[]\n",
    "    for f in files:\n",
    "        tumble = float(extract_floats(f)[0])\n",
    "        with h5py.File(f, \"r\") as fin:\n",
    "          count = 0\n",
    "          for key in fin.keys():\n",
    "              img = fin[key][:]\n",
    "              img = img.reshape((img.shape[0], img.shape[1],1))\n",
    "              shape = img.shape\n",
    "              inputs.append(img)\n",
    "              outputs.append(tumble)\n",
    "              count+=1\n",
    "\n",
    "    # Scramble the dataset\n",
    "    order = np.arange(len(outputs)).astype(int)\n",
    "    order = np.random.permutation(order)\n",
    "    return np.array(inputs)[order],np.array(outputs)[order],shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,shape = data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test train split\n",
    "last = int(len(x)*0.2)\n",
    "x_train, y_train = x[:-last], y[:-last]\n",
    "x_val,y_val = x[-last:],y[-last:]\n",
    "\n",
    "print(\"Size of training data: \", len(x_train))\n",
    "print(\"Size of validation data: \", len(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "name = \"modelName\"\n",
    "model = tf.keras.models.load_model(f'../models/{name}.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a layer and create partial model\n",
    "layerNum = 0\n",
    "\n",
    "print(model.layers[layerNum])\n",
    "model_part = Model(\n",
    "  inputs=model.layers[0].input,\n",
    "  outputs=model.layers[layerNum].output)\n",
    "\n",
    "intermed_output = model_part(x_train)\n",
    "intermed_output.shape\n",
    "\n",
    "# Get kernels and biases from original model\n",
    "kernels, biases = model.layers[layerNum].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on validation set\n",
    "prediction = model_part.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosea frame number from validation set (ideally with percolation), then outputs each kernel in layer and it's output\n",
    "example = 39\n",
    "\n",
    "print(y_val[example])\n",
    "\n",
    "for n in range(3):\n",
    "    plt.subplot(2,3,n+1)\n",
    "    plt.imshow(kernels[n].squeeze())\n",
    "    plt.title(f\"Kernel {n}\")\n",
    "\n",
    "    plt.subplot(2,3,n+4)\n",
    "    plt.imshow(prediction[example][:,:,n])\n",
    "    plt.title(f\"It's output\")\n",
    "\n",
    "plt.text(-50,-70,\"Third layer: conv_2d_1\")\n",
    "\n",
    "# plt.savefig(\"thirdLayerOutputNew.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
